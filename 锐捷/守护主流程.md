# 守护服务流程梳理
1. 进程启动时，加载配置文件
- 由application.yml中的配置决定存储所有的位置，如果部署到环境上，存放在 /ibnsdata 目录下，此目录是原来部署中不存的，需要新增
- 在开发调试阶段，配置在 target/data 目录下
- 目录的层次结构
```
ROOT				
	conf			
		cluster.json		
	node-config
		cockroach		
			certs	
		zookeeper		
			conf	
		kafka		
			conf	
	node-data
		cockroach		
			data	
			log	
		zookeeper		
			data	
			log	
		kafka		
			data	
			log	  
	cluster-config
		172.18.135.11		
			cockroach	
				certs
			zookeeper	
				conf
			kafka	
				conf
		172.18.135.12		
			cockroach	
				certs
			zookeeper	
				conf
			kafka	
				conf
		172.18.135.13		
			cockroach	
				certs
			zookeeper	
				conf
			kafka	
				conf
	cluster-distribution			
		172.18.135.11.zip		
		172.18.135.12.zip		
		172.18.135.13.zip		
	import-data
	    controller
	    cockroach
	    zookeeper
	    kafka
	export-data
	    controller
	    cockroach
	    zookeeper
	    kafka
    backup-data
        controller
        cockroach
        zookeeper
    restore-data
        controller
        cockroach
        zookeeper
	import-data-archive
	    xxxxxxxxxxxxxx.zip
    export-data-archive
        xxxxxxxxxxxxxx.zip
    backup-data-archive
	    xxxxxxxxxxxxxx.zip
    restore-data-archive
        xxxxxxxxxxxxxx.zip
```
- 二进制文件位于部署包中
```
  - resources
     - bin
        - cockroach 
        - zookeeper
        - kafka
```
1.1 如果配置文件不存在，则创建，默认的配置文件为

```
{
    "cluster": {
        "datetime": "Wed Oct 24 2018 11:19:25 GMT+0800", //该字段以Jackson保存的时间格式为准
        "nodes": ["127.0.0.1"],
        "decommissionNodes": [],
        "clusterConfigReady": true,
        "nodeConfigReady": true,
        "nodeIsMaster": true,
        "nodeIsRejoin": true
    },
    "history": [
    ]
}
```
1.2 如果集群已经组建，则配置文件的格式为
```
{
    "cluster": {
        "datetime": "Wed Oct 24 2018 11:19:25 GMT+0800", //该字段以Jackson保存的时间格式为准
        "nodes": ["172.18.135.11", "172.18.135.12", "172.18.135.13"],
        "decommissionNodes": ["172.18.135.14", "17.28.135.15"]
    },
    "history": [
        {
            "datetime": "Wed Oct 24 2018 11:19:25 GMT+0800", //该字段以Jackson保存的时间格式为准
            "cluster": ["127.0.0.1"]
        }
    ]
    
}
```
1.3 如果发生过集群成员的变更，在主结点有当前最后一次的变更记录
```
{
    "cluster": {
        "datetime": "Wed Oct 24 2018 11:19:25 GMT+0800", //该字段以Jackson保存的时间格式为准
        "nodes": ["172.18.135.11", "172.18.135.12", "172.18.135.13"],
        "decommissionNodes": ["172.18.135.14", "17.28.135.15"]
    },
    "history": [
        {
            "datetime": "Wed Oct 24 2018 11:19:25 GMT+0800", //该字段以Jackson保存的时间格式为准
            "nodes": ["127.0.0.1"],
            "decommissionNodes": [],
        }
    ]
    
}
```
1.4 由于Cockroach数据库不支持退化，所以在当前的守护服务中，退化将不被支持
- **但是需要提供辅助手段用于集群的退化**
- **待分析**
1.5 由于Cockorach数据库的成员变更，需要大多数的成员在线，<font color="red">因此对于退化的流程</font>
- **如果需要退化两个结点，需要验证可行性**
- **假设可行**, 先使用命令先退化结点，然后再加入结点，在这种情况下集群会产生5个结点，待全退化后，需要将两个结点移除，这个过程中会产生额外的两次证书分发
1.6 完成退化的集群重新分发证书，需要有一个因素来触发。则需要从结点定期从主结点获取退化的状态，如果发生集群变更，则需要重新请求证书或其他配置文件，然后重新下载
- **需要一个定时器定期检查主结点的情况**
- **待确认接口**
1.7 分发事件 ConfigurationBeforeInitEvent, ConfiguraitonAfterInitEvent, ConfigurationBeforeChangeEvent, ConfigurationAfterChangeEvent

2. 对于单结点的初始化，为了避免产生自己对自己的HTTP请求导致问题，所以流程区别于集群状态下的初始化
- 框架定义了中间件守护需要实现的方法，接口包含
    - 启动 startServer
    - 停止 stopServer
    - 状态检查 checkServer
    - 创建集群 createCluster 
    - 加入集群 joinCluster
    - 重新加入集群 rejoinCluster
    - 集群退化 decommisionCluster
    - 导出数据 exportData
    - 导入数据 importData
    - 备份数据 backupData
    - 还原数据 restoreData
- 对于中间件的操作，需要文件路径上下文，包括
    - 应用程序目录 
    - 集群配置工作目录
    - 集群配置分发目录
    - 集群配置分发指定节点的文件
    - 结点配置目录
    - 结点数据目录
    - 导入数据工作目录
    - 导出数据工作目录
    - 备份数据工作目录
    - 还原数据工作目录
    - 导入数据归档目录
    - 导出数据归档目录
    - 备份数据归档目录
    - 还原数据归档目录
    - 导入数据归档文件
    - 导出数据归档文件
    - 备份数据归档文件
    - 还原数据归档文件
- 对于中间件的操作，需要了解集群的状态，包括
    - 集群的成员列表
    - 集群的退化成员列表
    - 集群最新变更的时间

3. 守护服务启动
- 检查集群配置是否存在
    - 如果不存在，则创建默认的配置并加载
    - 如果已存在，则加载配置
- 获取中间件列表
    - Cockroach
    - Zookeeper
    - Kafka
    - Controller 仅实现了备份，还原操作
- 检查集群配置是否已经生效
    - 如果未生效
        - 遍历所有的中间件，强制执行中止操作
        - 检查当前结点身份，如果是主结点
            - 遍历所有的中间件，执行创建集群的动作
            - 遍历所有的结点列表，将结点的配置打包到归档目录
            - 更新集群配置中的 clusterConfigReady
            - 复制当前结点的配置到结点配置文件夹
            - 使用创建集群身份启动
                - Cockroach，不删除数据文件夹，以新的集群参数启动。执行成员退化的操作
                - Zookeeper，不删除数据文件夹，避免数据不一致性，以新的集群参数启动
                - Kafka，不删除数据文件夹，避免数据不一致性，以新的集群参数启动
            - 如果退化成员列表还存在，则需要执行退化的操作
                - Cockroach，使用退化命令
                - Zookeeper，无影响
                - Kafak, 无影响
                - 集群退化成功后，更新集群退化成员列表，更新 clusterConfigReady 为 false
            - 如果 clusterConfigReady 为false, 则重新执行集群的初始化
        - 如果非主结点
            - 访问主结点的HTTP接口，下载结点的配置数据
            - **上述步骤需要不断重试直到成功**
            - 是否是重新加入之前的集群，如果是
                - 遍历所有的中间件，执行重新加入集群的动作
                    - Cockroach，重新加入集群，意味着不删除数据文件夹，以新的集群参数启动
                    - Zookeeper，重新加入集群，也会删除数据文件夹，避免数据不一致性，以新的集群参数启动
                    - Kafka，重新加入集群，也会删除数据文件夹，避免数据不一致性，以新的集群参数启动
            - 如果不是，则是加入一个新的集群
                - 遍历所有的中间件，执行加入集群的动作
                    - Cockroach，加入集群，删除数据文件夹，以新的集群参数启动
                    - Zookeeper，加入集群，删除数据文件夹，以新的集群参数启动
                    - Kafka，加入集群，删除数据文件夹，以新的集群参数启动
            - 如果退化成员列表有值，则不断的调用主结点的HTTP接口，检查退化状态是否完成
            - **重复上面的请求直到成功**
            - 更新集群成员/退化成员列表，并更新 nodeConfigReady 为 false
            - 返回流程的初始状态，则重新执行集群的初始化
- 如果集群配置已经生效
    - 重启结点
- 启动定时器，检查控制器的集群状态

4. 定时器逻辑
- 获取控制器的集群状态
- 和配置文件中的集群状态比较
    - 如果集群成员列表完全一致，则跳过
    - 如果集群的成员相同，但是顺序不同，则跳过。**这种情况下是否需要做其他的处理**
    - 如果集群的成员数量不同
        - 停止所有的Webapp
        - 原来是单结点，现在是多结点
            - 执行3中的集群初始化逻辑
        - 原来是多结点，现在也是多结点
            - 判断结点数据是否相同，如果相同，表示集群成员变更 
                - 识别退化的成员列表
                - 识别集群的成员列表
                - 更新集群的配置，设置 clusterConfigReady, nodeConfigReady 为 false
                - 执行3中的集群初始化逻辑
            - 判断新的结点数据是否大于原来的结点数量 ，如果是，则表示集群成员扩充
                - 打印告警，表示这种操作在支持的场景列表中不存在，是否程序逻辑错误或控制器接口异常导致
                - 识别退化的成员列表
                - 识别集群的成员列表
                - 更新集群的配置，设置 clusterConfigReady, nodeConfigReady 为 false
                - 执行3中的集群初始化逻辑
            - 如果新的结点数小于原来的结点数量
                - 打印错误，表示这种场景一定不支持，可能会导致数据库缺少足够的成员无法正常启动
                - **如果发生这种情况，应当如何对付，需要提供恢复的指引**
        - 启动所有的Webapp

5. 中间件相关的配置
- Cockroach 
    - 需要初始化的数据库、用户名、密码
- Zookeeper
- Kafka
    - 需要初始化的主题


6. 领域模型
- Cluster
    - cluster
        - datetime
        - nodes
        - decommisionNodes
        - clusterConfigReady
        - nodeConfigReady
        - currentNodeIsMaster
        - currentClusterIsEntirelyNew
    - history
        - 保存所有的 cluster 变更记录，用于备查
- ControllerCluster
    - output
        - clusterIpList
            - keyUuid
            - clusterName
            - isOnline
            - controllerIp
            - clusterIndex
- CockroachCluster
    - nodes
        - host
        - address
        - port
        - version
        - startedAt
        - updatedAt
        - isLive
- WebApp
    - path
    - status
    - sessions
    - displayName


- 全局有一个Context，然后根据每个中间件会产生一个Context
- MiddlewareContext
    - 应用程序目录 binPath
    - 集群配置工作目录 clusterConfigFolder
    - 集群配置分发目录 clusterConfigDistrictionFolder
    - 集群配置分发指定节点的文件 clusterConfigDistituionFile
    - 结点配置目录 nodeConfigFolder
    - 结点数据目录 nodeDataFolder
    - **必须在导入、导出、备份、还原相关的流程中使用**
    - 导入数据工作目录 importDataWorkingFolder  
    - 导出数据工作目录 exportDataWorkingFolder
    - 备份数据工作目录 backupDataWorkingFolder
    - 还原数据工作目录 restoreDataWorkingFolder
    - 导入数据归档目录 importDataArchiveFolder
    - 导出数据归档目录 exportDataArchiveFolder
    - 备份数据归档目录 backupDataArchiveFolder
    - 还原数据归档目录 restoreDataArchiveFolder
    - 导入数据归档文件 importDataArchiveFile
    - 导出数据归档文件 exportDataArchiveFile
    - 备份数据归档文件 backupDataArchiveFile
    - 还原数据归档文件 restoreDataArchiveFile


- CockroachConfiguration
    - clusterOptions
        - cache
        - maxSqlMemeory
        - port
        - httpPort
    - operationOptions
        - startServer
            - timeout
            - successFilter
            - failFilter
        - stopServer
        - checkServer
        - createCluster
        - joinCluster
        - rejoinCluster
        - decommisionCluster
        - exportData
        - importData
        - backupData
        - restoreData
    - databases
        - uaa
            - name
            - username
            - password
        - onc
        - ...
        - 

- KafkaConfiguration
    - clusterOptions
        - **待补充**
    - operationOptions
        - startServer
            - timeout
            - successFilter
            - failFilter
        - stopServer
        - checkServer
        - createCluster
        - joinCluster
        - rejoinCluster
        - decommisionCluster
        - exportData
        - importData
        - backupData
        - restoreData 
    - topics
        - name
- ZookeeperConfiguration
    - clusterOptions
        - **待补充**
    - operationOptions
        - startServer
            - timeout
            - successFilter
            - failFilter
        - stopServer
        - checkServer
        - createCluster
        - joinCluster
        - rejoinCluster
        - decommisionCluster
        - exportData
        - importData
        - backupData
        - restoreData
    
7. MiddlewareService 
- 启动 startServer
- 停止 stopServer
- 状态检查 checkServer
- 创建集群 createCluster 
- 加入集群 joinCluster
- 重新加入集群 rejoinCluster
- 集群退化 decommisionCluster
- 导出数据 exportData
- 导入数据 importData
- 备份数据 backupData
- 还原数据 restoreData

8. MiddlewareManagerService
- 启动 startServer
- 停止 stopServer
- 状态检查 checkServer
- 创建集群 createCluster 
- 加入集群 joinCluster
- 重新加入集群 rejoinCluster
- 集群退化 decommisionCluster
- 导出数据 exportData
- 导入数据 importData
- 备份数据 backupData
- 还原数据 restoreData

9. REST接口
- /v1/cluster/config/actions/download
- /v1/cluster/data/actions/import
- /v1/cluster/data/actions/export
- /v1/cluster/data/actions/backup
- /v1/cluster/data/actions/restore

10. 事件管理
- BeforeStartServerEvent
- AfterStartServerEvent
- xxx
- xxx


curl -H "Content-Type: application/json" -d "{\"nodes\": [\"0.0.0.0\"],\"currentNode\": \"0.0.0.0\" }" http://localhost:8080/guard/v1/config/actions/download -o test.zip



11. MiddlewareContext
```
@Data
@NoArgsConstructor
@AllArgsConstructor
public class MiddlewareContext {
    /**
     * 集群配置文件路径
     * 默认为 conf
     * 即集群的配置文件为 conf/cluster.json
     */
    protected String configurationFolder;

    /**
     * 二进制文件的路径，默认为
     * 开发时 target/binary
     * TODO: 执行时的路径是否需要移到webapp外？
     */
    protected String binaryFolder;

    protected String tomcatWebappFolder;

    /**
     * 集群配置的工作目录
     * 默认为 cluster-config
     */
    protected String clusterConfigWorkingFolder;

    /**
     * 集群配置的分发目录
     * 默认为 cluster-distribution
     */
    protected String clusterConfigDistributionFolder;

    /**
     * 结点的配置目录
     * 默认为 node-config
     */
    protected String nodeConfigFolder;

    /**
     * 结点的数据目录
     * 默认为 node-data
     */
    protected String nodeDataFolder;

    /**
     * 导入数据的工作目录，默认为
     * import-data
     */
    protected String importDataWorkingFolder;

    /**
     * 导出数据的工作目录，默认为
     * export-data
     */
    protected String exportDataWorkingFolder;

    /**
     * 备份数据的工作目录，默认为
     * backup-data
     */
    protected String backupDataWorkingFolder;

    /**
     * 还原数据的工作目录，默认为
     * restore-data
     */
    protected String restoreDataWorkingFolder;

    /**
     * 导入数据的归档目录，默认为
     * import-data-archive
     */
    protected String importDataArchiveFolder;

    /**
     * 导出数据的归档目录，默认为
     * export-data-archive
     */
    protected String exportDataArchiveFolder;

    /**
     * 备份数据的归档目录，默认为
     * backup-data-archive
     */
    protected String backupDataArchiveFolder;

    /**
     * 还原数据的归档目录，默认为
     * restore-data-archive
     */
    protected String restoreDataArchiveFolder;

    /**
     * 导入数据的归档文件，默认
     * import-data-archive/<时间戳>.zip
     */
    protected String importDataArchiveFile;

    /**
     * 导出数据的归档文件，默认
     * export-data-archive/<时间戳>.zip
     */
    protected String exportDataArchiveFile;

    /**
     * 备份数据的归档文件，默认
     * backup-data-archive/<时间戳>.zip
     */
    protected String backupDataArchiveFile;

    /**
     * 还原数据的归档文件，默认
     * restore-data-archive/<时间戳>.zip
     */
    protected String restoreDataArchiveFile;

    /**
     * 根据结点IP获取相应的配置文件
     *
     * @param node 结点的IP
     * @return 结点配置文件的全路径 cluster config distribution file
     */
    public String getClusterConfigDistributionFile(String node) {
        return clusterConfigDistributionFolder + Constants.PATH_SPLITER + node + Constants.ZIP_EXTENSION;
    }

    /**
     * 获取结点的配置文件夹
     *
     * @param node 结点IP
     * @return 结点的配置文件夹全路径 cluster config folder
     */
    public String getClusterConfigFolder(String node) {
        return clusterConfigWorkingFolder + Constants.PATH_SPLITER + node;
    }


    /**
     * Get middleware cluster config file string.
     *
     * @return the string
     */
    public String getMiddlewareClusterConfigFile(){
        return configurationFolder + Constants.CLUSTER_CONFIGURATION_FILE;
    }

    /**
     * Get middleware cluster config history file string.
     *
     * @return the string
     */
    public String getMiddlewareClusterConfigHistoryFile (){
        return configurationFolder + Constants.CLUSTER_CONFIGURATION_HISTORY_FILE;
    }


}
```

12. MiddlewareCluster
```
@Data
@AllArgsConstructor
@NoArgsConstructor
@Builder
@Slf4j
public class MiddlewareCluster {

    /**
     * The Uuid.
     */
    protected String uuid;

    /**
     * 集群组建的时间
     */
    protected Date dateTime;

    /**
     * 当前结点的IP
     */
    protected String currentNode;

    /**
     * 结点IP列表
     */
    protected List<String> nodes;

    /**
     * Decommission Nodes 的清单
     */
    protected List<String> decommissionNodes;

    /**
     * 集群配置是否已准备好
     * TODO: 可以考虑和 nodeConfigReady 合并
     */
    protected Boolean clusterConfigReady;

    /**
     * 结点配置是否已经准备好
     */
    protected Boolean nodeConfigReady;

    /**
     * 当前结点是否是主结点
     */
    protected Boolean currentNodeIsMaster;

    /**
     * 当前集群是否是全新的集群
     */
    protected Boolean currentClusterIsEntirelyNew;

    /**
     * 获取主结点的IP
     * TODO: 需要增加异常处理
     *
     * @return 主结点的IP master node
     */
    public String getMasterNode() {
        return getNodes().get(Constants.MASTER_NODE_INDEX);
    }

    /**
     * 获取结点列表，为了避免返回 null 带来的程序异常
     *
     * @return 返回结点列表 nodes
     */
    public List<String> getNodes() {
        if (nodes == null) {
            nodes = new ArrayList<>();
        }
        return nodes;
    }

    /**
     * 获取decommission的结点列表，为了避免返回 null 带来的程序异常
     *
     * @return the decommission nodes
     */
    public List<String> getDecommissionNodes() {
        if (decommissionNodes == null) {
            decommissionNodes = new ArrayList<>();
        }
        return decommissionNodes;
    }


    /**
     * Current node is master boolean.
     *
     * @return the boolean
     */
    public Boolean getCurrentNodeIsMaster(){
        return StringUtils.equalsIgnoreCase(getMasterNode(), currentNode);
    }


    /**
     * Is bootstrap startup boolean.
     *
     * @return the boolean
     */
    public Boolean isBootstrapStartup (){
        if (Constants.MAP_SIZE_1.equals(getNodes().size()) && !getClusterConfigReady() && !getNodeConfigReady()){
            log.info("single node bootstrap startup");
            return Boolean.TRUE;
        }else if (getCurrentNodeIsMaster() && !getClusterConfigReady()){
            log.info("master node bootstrap startup");
            return Boolean.TRUE;
        }else if (!getCurrentNodeIsMaster() && !getNodeConfigReady()){
            log.info("slave node bootstrap startup");
            return Boolean.TRUE;
        }else{
            log.debug("Not bootstrap startup ");
            return Boolean.FALSE;
        }
    }

    /**
     * Gets current cluster is entirely new.
     *
     * @return the current cluster is entirely new
     */
    public Boolean getCurrentClusterIsEntirelyNew() {
        return BooleanUtils.isTrue(currentClusterIsEntirelyNew);
    }


    /**
     * Gets uuid.
     *
     * @return the uuid
     */
    public String getUuid() {
        return StringUtils.defaultIfBlank(uuid, UUID.randomUUID().toString());
    }

}

```

13. 配置文件示例
```
# 假定
# 守护服务的部署路径为 /user/rgonc/RG-ONC-2.1.0/RG-ONC-CAMPUS-CLOUD-Web_2.0/ibnsapps/guard
# 数据文件夹的根路径为 /ibnsdata/guard

# 相关的文件夹
binaryFolder=/user/rgonc/RG-ONC-2.1.0/RG-ONC-CAMPUS-CLOUD-Web_2.0/ibnsapps/guard/binary

# postgresql 二进制包的路径
postgresqlBinaryFolder=/user/rgonc/RG-ONC-2.1.0/RG-ONC-CAMPUS-CLOUD-Web_2.0/ibnsapps/guard/binary/postgresql

# 如果需要取指定结点的postgresql的配置配置，目录为
# ${clusterConfigWorkingFolder}/${IP}/postgresql
# 例如
# 单机时 /ibnsdata/guard/cluster-config/127.0.0.1/postgresql
# 集群时 /ibnsdata/guard/cluster-config/172.18.135.11/postgresql
clusterConfigWorkingFolder=/ibnsdata/guard/cluster-config

nodeConfigFolder=/ibnsdata/guard/node-config

postgresqlNodeConfigFolder=/ibnsdata/guard/node-config/postgresql

nodeDataFolder=/ibnsdata/guard/node-data

postgresqlNodeDataFolder=/ibnsdata/guard/node-data/postgresql

# 集群信息
# 如果是单机启动，则currentNode为127.0.0.1
# 如果是集群启动，则是对应到控制器中的IP
currentNode=172.18.135.11

nodes=172.18.135.11,172.18.135.12,172.18.135.13

# 是否集群主结点
# 如果是，则对应到组建集群里的动作为 createCluster -> start
# 正常启动的动作是 start
currentNodeIsMaster=true

# 是否属于集群新成员 
# 如果 currentNodeIsMaster=false
#     如果 currentClusterIsEntirelyNew=true，则对应集群组建的动作为 joinNewCluster
#     如果 currentClusterIsEntirelyNew=false，则对应集群组建的动作为 rejoinCluster
# 如果 currentNodeIsMaster=true 则可以不用管这个选项
currentClusterIsEntirelyNew=true

#集群成员ID，从0开始编号 
currentNodeIndex=0

#如果 nodesCount=1 表示是单机，其他是集群
nodesCount=3
```